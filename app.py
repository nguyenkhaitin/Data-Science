# Streamlit & Giao di·ªán
import streamlit as st

# D·ªØ li·ªáu & x·ª≠ l√Ω d·ªØ li·ªáu
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json

# Tr·ª±c quan h√≥a
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Ph√¢n t√≠ch th·ªëng k√™ & m√¥ h√¨nh chu·ªói th·ªùi gian
from scipy import stats
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import (
    SimpleExpSmoothing,
    Holt,
    ExponentialSmoothing
)

# ƒê√°nh gi√° m√¥ h√¨nh
from sklearn.metrics import mean_absolute_error, mean_squared_error 
import joblib
from streamlit_option_menu import option_menu



# ƒê√°nh gi√° m√¥ h√¨nh
from models import (
    create_dataset,
    train_lstm_model_from_csv,
    predict_future_gru,
    predict_future
)

# Import t·∫•t c·∫£ c√°c h√†m t·ª´ models_goodnine.py
from models_goodnine import (
    create_dataset_uni,
    create_dataset_multi,
    add_technical_indicators,
    train_dual_branch_model,
    train_model_optimized,
    predict_goodnine,
    predict_full_from_scratch
)


from functions import (
    # X·ª≠ l√Ω d·ªØ li·ªáu
    safe_float,
    calculate_statistics,

    # Bi·ªÉu ƒë·ªì th·ªëng k√™
    plot_price_movement_chart,
    plot_candlestick_chart,
    plot_interactive_close_histogram,
    plot_interactive_volume_histogram,
    plot_growth_histogram,
    plot_close_vs_volume_scatter_with_correlation,
    plot_weekday_analysis_chart,
    plot_combined_chart_by_month,
    plot_volume_and_growth_by_weekday,
    plot_volume_and_growth_by_month,
    plot_total_traded_value_by_month,
    plot_total_and_avg_close_combined_by_month,
    plot_total_traded_value_by_quarter,
    plot_close_boxplot,
    plot_interactive_autocorrelation,
    plot_interactive_decomposition,
    plot_rsi,
    plot_log_return,
    plot_price_and_volatility,
    plot_momentum_5,
    plot_macd,
    plot_bollinger_bands,

    # M√¥ h√¨nh d·ª± b√°o
    create_adj_close_multi_ma_chart_with_prediction,
    calc_ma_prediction_with_real_test,
    create_adj_close_es_chart_with_prediction,
    create_adj_close_holt_chart_with_prediction,
    create_adj_close_holt_winters_chart_with_prediction,
    apply_es_monthly,
    apply_holt_monthly,
    apply_holt_winters_monthly,
)


# PH·∫¢I ƒê·ªÇ NGAY ƒê√ÇY!
st.set_page_config(page_title="Stock Prediction", page_icon="üìà", layout="wide")

def load_css():
    with open("styles.css", encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

load_css()  # G·ªçi ngay sau khi import th∆∞ vi·ªán




def main():
    ma_period = None  # Kh·ªüi t·∫°o ma_period b·∫±ng None
    # ƒê·ªãnh nghƒ©a forecast_days ·ªü ƒë√¢y
    forecast_days = 7  # Ho·∫∑c b·∫•t k·ª≥ gi√° tr·ªã n√†o b·∫°n mu·ªën


    with st.sidebar:
        # Th√™m Google Fonts v√†o giao di·ªán
        st.markdown("""
        <h1 style='
            text-align:center; 
            font-family:Poppins, Roboto, sans-serif; 
            color:#007bff; 
            font-weight: 700; 
            text-transform: uppercase;
            background: linear-gradient(90deg, #007bff, #00c6ff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        '>
        ·ª®ng D·ª•ng Ph√¢n T√≠ch <br> Ch·ª©ng Kho√°n
        </h1>
        """, unsafe_allow_html=True)

        selected_tab = option_menu(
            menu_title=None,
            options=["Statistics", "Traditional Models", "Machine Learning", "Optimized ML", "Model Performance"],
            icons=["bar-chart", "activity", "cpu", "list"],
            menu_icon="cast",
            default_index=0,
            styles={
                "container": {
                    "padding": "0!important",
                    "background-color": "#E8FCFF",
                    "font-family": "Poppins, Roboto, sans-serif",
                    "border": "none"
                },
                "icon": {
                    "color": "#007bff",
                    "font-size": "20px",
                    "transition": "transform 0.3s ease"
                },
                "nav-link": {
                    "font-size": "18px",
                    "text-align": "left",
                    "margin": "6px auto",  # CƒÉn gi·ªØa v√† c√≥ kho·∫£ng c√°ch r√µ h∆°n
                    "border-radius": "16px", 
                    "padding": "10px 16px",
                    "width": "85%",  # Gi·∫£m chi·ªÅu r·ªông ƒë·ªÉ hi·ªÉn th·ªã r√µ bo g√≥c
                    "color": "#333333",
                    "background-color": "#ffffff",
                    "transition": "all 0.3s ease",
                    "font-family": "Poppins, Roboto, sans-serif",
                    "font-weight": "500",
                    "box-shadow": "0 4px 12px rgba(0, 0, 0, 0.05)"
                },
                "nav-link:hover": {
                    "background-color": "#d0f0f8",
                    "color": "#007bff",
                    "transform": "scale(1.05)",
                    "box-shadow": "0 8px 24px rgba(0, 123, 255, 0.2)"
                },
                "nav-link-selected": {
                    "background-color": "#007bff",
                    "color": "#ffffff",
                    "font-weight": "600",
                    "border-radius": "24px",  # Bo tr√≤n nhi·ªÅu h∆°n khi ch·ªçn
                    "padding": "14px 24px",   # Ph√≥ng to tab khi ch·ªçn
                    "width": "90%",           # Gi·ªØ chi·ªÅu r·ªông ƒë·ªÉ vi·ªÅn hi·ªán r√µ
                    "box-shadow": "0 12px 32px rgba(0, 123, 255, 0.4)",
                    "transform": "scale(1.1)" # Hi·ªáu ·ª©ng ph√≥ng to khi ch·ªçn
                },
                "icon-color": "#007bff",
                "icon-color-active": "#ffffff"
            }
        )






    # Home Tab
    if selected_tab == "Statistics":
        # D√πng HTML ƒë·ªÉ cƒÉn gi·ªØa ti√™u ƒë·ªÅ ch√≠nh
        st.markdown(
        """
        <h1 style="text-align:center;">TH·ªêNG K√ä M√î T·∫¢</h1>
        """,
        unsafe_allow_html=True
        )
        st.subheader('TH√îNG S·ªê ƒê·∫¶U V√ÄO')

        # L·∫•y danh s√°ch c√°c file CSV trong th∆∞ m·ª•c dataset
        dataset_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dataset")
        csv_files = [f for f in os.listdir(dataset_dir) if f.endswith('.csv')]

        import datetime
        col1, col2, col3 = st.columns(3)
        with col1:
            symbol = st.text_input('M√£ ch·ª©ng kho√°n', 'CRM')
        with col2:
            start_date = st.date_input(
                'Ng√†y b·∫Øt ƒë·∫ßu',
                datetime.date(2005, 1, 1),
                min_value=datetime.date(1900, 1, 1),   # ƒê·∫∑t ng√†y nh·ªè nh·∫•t
                max_value=datetime.date(2050, 12, 31)  # ƒê·∫∑t ng√†y l·ªõn nh·∫•t
            )
        with col3:
            end_date = st.date_input(
                'Ng√†y k·∫øt th√∫c',
                datetime.date(2022, 7, 12),
                min_value=datetime.date(1900, 1, 1),
                max_value=datetime.date(2050, 12, 31)
    )


        if st.button('PH√ÇN T√çCH'):
            # T·∫°o danh s√°ch m√£ ch·ª©ng kho√°n t·ª´ t√™n file (lo·∫°i b·ªè .csv v√† vi·∫øt hoa)
            available_symbols = [f.replace('.csv', '').upper() for f in csv_files]


            if symbol.upper() in available_symbols:
                file_name = f"{symbol.upper()}.csv"
                file_path = os.path.join(dataset_dir, file_name)

                # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV t∆∞∆°ng ·ª©ng
                df = pd.read_csv(file_path)
                df['Date'] = pd.to_datetime(df['Date'])
                df.set_index('Date', inplace=True)

                # Chuy·ªÉn ng√†y
                start_dt = pd.to_datetime(start_date)
                end_dt = pd.to_datetime(end_date)

                # L·ªçc d·ªØ li·ªáu
                df_filtered = df[(df.index >= start_dt) & (df.index <= end_dt)].copy()
                df_filtered = df_filtered.reset_index()  # ƒë·ªÉ c√≥ c·ªôt 'Date'


                # T√≠nh to√°n ch·ªâ s·ªë
                mean_price = df_filtered['Close'].mean()
                max_price = df_filtered['Close'].max()
                max_date = df_filtered.loc[df_filtered['Close'].idxmax(), 'Date'].strftime('%Y-%m-%d')
                min_price = df_filtered['Close'].min()
                min_date = df_filtered.loc[df_filtered['Close'].idxmin(), 'Date'].strftime('%Y-%m-%d')
                avg_growth = df_filtered['Close'].pct_change().mean() * 100
                avg_volatility = (df_filtered['High'] - df_filtered['Low']).mean()
                market_cap_avg = (df_filtered['Close'] * df_filtered['Volume']).mean()
                log_return = np.log(df_filtered['Close'] / df_filtered['Close'].shift(1)).dropna()
                avg_log_return = log_return.mean()
                std_dev = df_filtered['Close'].std()
                coef_variation = std_dev / mean_price

                # CSS cho metric cards
                st.markdown("""
                <style>
                .metric-card {
                    border: 1px solid #e0e0e0;
                    border-radius: 12px;
                    padding: 20px;
                    text-align: center;
                    background-color: #ffffff;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.05);
                    margin-bottom: 15px;
                }
                .metric-label {
                    font-weight: 600;
                    font-size: 18px;
                    color: #444;
                    margin-bottom: 8px;
                }
                .metric-value {
                    font-size: 24px;
                    font-weight: bold;
                    color: #1a73e8;
                }
                </style>
                """, unsafe_allow_html=True)


            st.subheader(f"K·∫æT QU·∫¢ PH√ÇN T√çCH: `{symbol.upper()}`")

            with st.expander("**TH·ªêNG K√ä M√î T·∫¢**", expanded=True):
                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ s·ªë th·ªëng k√™ ƒë√°ng ch√∫ √Ω</div>", unsafe_allow_html=True)

                # H√†ng 1
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Gi√° trung b√¨nh</div>
                        <div class="metric-value">{mean_price:.2f}</div>
                    </div>""", unsafe_allow_html=True)
                with col2:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Gi√° cao nh·∫•t</div>
                        <div class="metric-value">{max_price:.2f} ({max_date})</div>
                    </div>""", unsafe_allow_html=True)
                with col3:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Gi√° th·∫•p nh·∫•t</div>
                        <div class="metric-value">{min_price:.2f} ({min_date})</div>
                    </div>""", unsafe_allow_html=True)
                with col4:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">V·ªën h√≥a TB</div>
                        <div class="metric-value">{market_cap_avg:,.0f}</div>
                    </div>""", unsafe_allow_html=True)

                # H√†ng 2
                col5, col6, col7, col8 = st.columns(4)
                with col5:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Trung b√¨nh tƒÉng tr∆∞·ªüng</div>
                        <div class="metric-value">{avg_growth:.2f}%</div>
                    </div>""", unsafe_allow_html=True)

                with col6:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Trung b√¨nh bi·∫øn ƒë·ªông gi√°</div>
                        <div class="metric-value">{avg_volatility:.2f}</div>
                    </div>""", unsafe_allow_html=True)

                with col7:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">Log return trung b√¨nh</div>
                        <div class="metric-value">{avg_log_return:.4f}</div>
                    </div>""", unsafe_allow_html=True)


                with col8:
                    st.markdown(f"""<div class="metric-card">
                        <div class="metric-label">H·ªá s·ªë bi·∫øn thi√™n</div>
                        <div class="metric-value">{coef_variation:.2f}</div>
                    </div>""", unsafe_allow_html=True)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Tham s·ªë c∆° b·∫£n</div>", unsafe_allow_html=True)
                stats_df = calculate_statistics(df, start_date, end_date)
                st.dataframe(stats_df, use_container_width=True)

                # Hai bi·ªÉu ƒë·ªì Histogram (Close v√† Volume) ·ªü h√†ng tr√™n, chia 2 c·ªôt
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì Histogram gi√° ƒë√≥ng c·ª≠a</div>", unsafe_allow_html=True)
                    plot_interactive_close_histogram(df_filtered)

                with col2:
                    st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì Histogram s·ªë l∆∞·ª£ng giao d·ªãch</div>", unsafe_allow_html=True)
                    plot_interactive_volume_histogram(df_filtered)

                # Bi·ªÉu ƒë·ªì Histogram T·ª∑ l·ªá tƒÉng tr∆∞·ªüng ·ªü h√†ng d∆∞·ªõi, full width
                st.markdown("<div style='font-size:16px; font-weight:600; margin-top:20px;'>Bi·ªÉu ƒë·ªì Histogram T·ª∑ l·ªá tƒÉng tr∆∞·ªüng</div>", unsafe_allow_html=True)
                fig_growth_hist = plot_growth_histogram(df_filtered)
                st.plotly_chart(fig_growth_hist, use_container_width=True)



                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì Ph√¢n T√°n & T∆∞∆°ng Quan: Close vs Volume</div>", unsafe_allow_html=True)
                plot_close_vs_volume_scatter_with_correlation(df_filtered)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì h·ªôp ph√¢n ph·ªëi gi√° ƒë√≥ng c·ª≠a (Close)</div>", unsafe_allow_html=True)
                plot_close_boxplot(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o RSI ‚Äì ƒê·ªông l∆∞·ª£ng gi√° c·ªï phi·∫øu</div>", unsafe_allow_html=True)
                plot_rsi(df_filtered)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o MACD</div>", unsafe_allow_html=True)
                plot_macd(df_filtered)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o Log Return</div>", unsafe_allow_html=True)
                plot_log_return(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o Volatility</div>", unsafe_allow_html=True)
                plot_price_and_volatility(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o Momentum</div>", unsafe_allow_html=True)
                plot_momentum_5(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Ch·ªâ b√°o Bollinger Bands</div>", unsafe_allow_html=True)
                plot_bollinger_bands(df_filtered)




            with st.expander("üìå **PH√ÇN T√çCH CHU·ªñI TH·ªúI GIAN**", expanded=True):

                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÅu ƒë·ªì bi·∫øn ƒë·ªông gi√° ƒë√≥ng c·ª≠a v√† s·ªë l∆∞·ª£ng giao d·ªãch</div>", unsafe_allow_html=True)
                fig_price = plot_price_movement_chart(df, start_date, end_date)
                st.plotly_chart(fig_price, use_container_width=True)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì N·∫øn Gi√° C·ªï Phi·∫øu</div>", unsafe_allow_html=True)
                fig_candle = plot_candlestick_chart(df, start_date, end_date)
                st.plotly_chart(fig_candle, use_container_width=True)

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì T·ªïng gi√° tr·ªã giao d·ªãch theo th√°ng (Close √ó Volume)</div>", unsafe_allow_html=True)
                    plot_total_traded_value_by_month(df_filtered)

                with col2:
                    st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì T·ªïng gi√° tr·ªã giao d·ªãch theo qu√Ω (Close √ó Volume)</div>", unsafe_allow_html=True)
                    plot_total_traded_value_by_quarter(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì T·ªïng & Trung b√¨nh gi√° ƒë√≥ng c·ª≠a theo th√°ng</div>", unsafe_allow_html=True)
                plot_total_and_avg_close_combined_by_month(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì ph√¢n t√≠ch theo th·ª© trong tu·∫ßn</div>", unsafe_allow_html=True)
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**üìà Gi√° ƒë√≥ng c·ª≠a & tƒÉng tr∆∞·ªüng**")
                    plot_weekday_analysis_chart(df_filtered)

                with col2:
                    st.markdown("**üìä Kh·ªëi l∆∞·ª£ng giao d·ªãch & tƒÉng tr∆∞·ªüng**")
                    plot_volume_and_growth_by_weekday(df_filtered)


                # ======= BI·ªÇU ƒê·ªí THEO TH√ÅNG TRONG NƒÇM =======
                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì ph√¢n t√≠ch theo th√°ng trong nƒÉm</div>", unsafe_allow_html=True)
                col3, col4 = st.columns(2)

                with col3:
                    st.markdown("**üìà Gi√° ƒë√≥ng c·ª≠a & tƒÉng tr∆∞·ªüng**")
                    plot_combined_chart_by_month(df_filtered)

                with col4:
                    st.markdown("**üìä Kh·ªëi l∆∞·ª£ng giao d·ªãch & tƒÉng tr∆∞·ªüng**")
                    plot_volume_and_growth_by_month(df_filtered)


                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì T·ª± t∆∞∆°ng quan</div>", unsafe_allow_html=True)
                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                plot_interactive_autocorrelation(df_filtered)

                st.markdown("<div style='font-size:16px; font-weight:600;'>Bi·ªÉu ƒë·ªì ph√¢n t√≠ch th√†nh ph·∫ßn chu·ªói th·ªùi gian (Time Series Decomposition)</div>", unsafe_allow_html=True)
                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                plot_interactive_decomposition(df_filtered)

                







    # Prediction Tab
    elif selected_tab == "Traditional Models":
        # D√πng HTML ƒë·ªÉ cƒÉn gi·ªØa ti√™u ƒë·ªÅ ch√≠nh
        st.markdown(
        """
        <h1 style="text-align:center;">PH√ÇN T√çCH M√î H√åNH D·ª∞ ƒêO√ÅN TRUY·ªÄN TH·ªêNG</h1>
        """,
        unsafe_allow_html=True
        )



        # L·∫•y danh s√°ch c√°c file CSV trong th∆∞ m·ª•c dataset
        dataset_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dataset")
        csv_files = [f for f in os.listdir(dataset_dir) if f.endswith('.csv')]

        selected_symbol = st.text_input("Nh·∫≠p m√£ ch·ª©ng kho√°n", "MSFT", key="selected_symbol").upper().strip()
        selected_file = f"{selected_symbol}.csv"

        # Ki·ªÉm tra xem ng∆∞·ªùi d√πng ƒë√£ ch·ªçn file hay ch∆∞a
        if selected_file:
            # ƒê∆∞·ªùng d·∫´n t·ªõi file CSV ƒë√£ ch·ªçn
            file_path = os.path.join(dataset_dir, selected_file)

            # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV ƒë√£ ch·ªçn
            df = pd.read_csv(file_path)

        # Ch·ªçn m√¥ h√¨nh d·ª± b√°o
        st.subheader("M√î H√åNH D·ª∞ ƒêO√ÅN")
        model_choice = st.selectbox("M√¥ h√¨nh:",
                                    ["Simple Moving Average",
                                    "Exponential Smoothing By Day",
                                    "Exponential Smoothing By Month",
                                    "Holt By Day", "Holt By Month",
                                    "Holt Winter By Day", "Holt Winter By Month"
                                    ])

        # Ch·ªçn th·ªùi gian d·ª± ƒëo√°n (ch·ªâ cho Simple Moving Average)
        if model_choice == "Simple Moving Average":
            st.subheader("TH·ªúI GIAN D·ª∞ ƒêO√ÅN")

            # 1. Nh·∫≠p nhi·ªÅu k·ª≥ h·∫°n MA, v√≠ d·ª•: 20,50,100
            ma_input = st.text_input("Nh·∫≠p c√°c k·ª≥ h·∫°n MA", "20,50,100", key="ma_input")


            # Chuy·ªÉn th√†nh list int, l·ªçc s·ªë h·ª£p l·ªá
            ma_windows = [int(x.strip()) for x in ma_input.split(",") if x.strip().isdigit() and int(x.strip()) > 0]
            if not ma_windows:
                st.warning("Vui l√≤ng nh·∫≠p √≠t nh·∫•t 1 k·ª≥ h·∫°n MA h·ª£p l·ªá.")

            # 2. Ch·ªçn th·ªùi gian d·ª± ƒëo√°n
            forecast_period = st.selectbox(
                "Th·ªùi gian d·ª± ƒëo√°n:",
                ["1 ng√†y", "1 tu·∫ßn (5 ng√†y)", "1 th√°ng (22 ng√†y)", "Kh√°c"]
            )

            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                forecast_days = custom_days
            else:
                forecast_days = {
                    "1 ng√†y": 1,
                    "1 tu·∫ßn (5 ng√†y)": 5,
                    "1 th√°ng (22 ng√†y)": 22,
                }[forecast_period]


        elif model_choice == "Exponential Smoothing By Day":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")
            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 ng√†y", "1 tu·∫ßn (5 ng√†y)",
                                                "1 th√°ng (22 ng√†y)", "Kh√°c"])
            
             # Trong ph·∫ßn Pred, th√™m thanh ƒëi·ªÅu ch·ªânh:
            smoothing_level = st.slider("Alpha (Smoothing Level)", 0.01, 1.0, 0.1, 0.01)

            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                ma_period = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1, step=1)
                # ƒê·∫£m b·∫£o kh√¥ng b·ªã None (number_input lu√¥n tr·∫£ v·ªÅ s·ªë, kh√¥ng None, tr·ª´ khi code kh√°c t√°c ƒë·ªông)
            else:
                ma_period = {
                    "1 ng√†y": 1,
                    "1 tu·∫ßn (5 ng√†y)": 5,
                    "1 th√°ng (22 ng√†y)": 22,
                }[forecast_period]

            try:
                ma_period = int(ma_period)
            except Exception:
                st.error("Vui l√≤ng nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n h·ª£p l·ªá!")
                st.stop()


        elif model_choice == "Exponential Smoothing By Month":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")

            seasonality_periods = st.number_input("Giai ƒëo·∫°n m√πa v·ª•", min_value=1, value=12, step=1)

            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 th√°ng", "6 th√°ng",
                                                "12 th√°ng", "Kh√°c"])
            
             # Trong ph·∫ßn Pred, th√™m thanh ƒëi·ªÅu ch·ªânh:
            alpha_es = st.slider("Alpha (Smoothing Level)", 0.01, 1.0, 0.1, 0.01)

            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                ma_period = custom_days  # G√°n custom_days cho ma_period n·∫øu ch·ªçn "Kh√°c"
            else:
                # G√°n ma_period d·ª±a tr√™n forecast_period ƒë√£ ch·ªçn
                ma_period = {
                    "1 th√°ng": 1,
                    "6 th√°ng": 6,
                    "12 th√°ng": 12,
                }[forecast_period]


        elif model_choice == "Holt By Day":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")
            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 ng√†y", "1 tu·∫ßn (5 ng√†y)",
                                                "1 th√°ng (22 ng√†y)", "Kh√°c"])

            st.subheader("Ch·ªçn h·ªá s·ªë alpha v√† beta:")
            alpha = st.slider("Alpha (Smoothing Level):", min_value=0.01, max_value=1.0, value=0.1, step=0.01)
            beta = st.slider("Beta (Smoothing Trend):", min_value=0.01, max_value=1.0, value=0.2, step=0.01)


            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                ma_period = custom_days  # G√°n custom_days cho ma_period n·∫øu ch·ªçn "Kh√°c"
            else:
                # G√°n ma_period d·ª±a tr√™n forecast_period ƒë√£ ch·ªçn
                ma_period = {
                    "1 ng√†y": 1,
                    "1 tu·∫ßn (5 ng√†y)": 5,
                    "1 th√°ng (22 ng√†y)": 22,
                }[forecast_period]

        elif model_choice == "Holt By Month":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")

            seasonality_periods = st.number_input("Giai ƒëo·∫°n m√πa v·ª•", min_value=1, value=12, step=1)

            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 th√°ng", "6 th√°ng",
                                                "12 th√°ng", "Kh√°c"])

            # Add sliders for Holt-Winters parameters
            st.subheader("Holt-Winters Parameters")
            alpha_holt = st.slider("Smoothing Level (Alpha)", 0.01, 1.0, 0.2, 0.01)
            beta_holt = st.slider("Smoothing Trend (Beta)", 0.01, 1.0, 0.1, 0.01)


            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                ma_period = custom_days  # G√°n custom_days cho ma_period n·∫øu ch·ªçn "Kh√°c"
            else:
                # G√°n ma_period d·ª±a tr√™n forecast_period ƒë√£ ch·ªçn
                ma_period = {
                    "1 th√°ng": 1,
                    "6 th√°ng": 6,
                    "12 th√°ng": 12,
                }[forecast_period]

        elif model_choice == "Holt Winter By Day":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")

            seasonality_periods = st.number_input("Giai ƒëo·∫°n m√πa v·ª•", min_value=1, value=252, step=1)

            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 ng√†y", "1 tu·∫ßn (5 ng√†y)",
                                                "1 th√°ng (22 ng√†y)", "Kh√°c"])

            st.subheader("Ch·ªçn h·ªá s·ªë alpha v√† beta:")
            alpha = st.slider("Alpha (Smoothing Level):", min_value=0.01, max_value=1.0, value=0.1, step=0.01)
            beta = st.slider("Beta (Smoothing Trend):", min_value=0.01, max_value=1.0, value=0.2, step=0.01)
            gamma = st.slider("Gamma (Smoothing Seasonality):", min_value=0.01, max_value=1.0, value=0.2, step=0.01)


            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                ma_period = custom_days  # G√°n custom_days cho ma_period n·∫øu ch·ªçn "Kh√°c"
            else:
                # G√°n ma_period d·ª±a tr√™n forecast_period ƒë√£ ch·ªçn
                ma_period = {
                    "1 ng√†y": 1,
                    "1 tu·∫ßn (5 ng√†y)": 5,
                    "1 th√°ng (22 ng√†y)": 22,
                }[forecast_period]

        elif model_choice == "Holt Winter By Month":
            st.subheader("Ch·ªçn th·ªùi gian d·ª± ƒëo√°n:")

            seasonality_periods = st.number_input("Giai ƒëo·∫°n m√πa v·ª•", min_value=1, value=12, step=1)

            forecast_period = st.selectbox("Th·ªùi gian:",
                                                ["1 th√°ng", "6 th√°ng",
                                                "12 th√°ng", "Kh√°c"])

            # Add sliders for Holt-Winters parameters
            st.subheader("Holt-Winters Parameters")
            alpha_hwm = st.slider("Smoothing Level (Alpha)", 0.01, 1.0, 0.2, 0.01)
            beta_hwm = st.slider("Smoothing Trend (Beta)", 0.01, 1.0, 0.1, 0.01)
            gamma_hwm = st.slider("Smoothing Seasonal (Gamma)", 0.01, 1.0, 0.1, 0.01)


            # N·∫øu ch·ªçn "Kh√°c", cho ph√©p nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n
            if forecast_period == "Kh√°c":
                custom_days = st.number_input("Nh·∫≠p s·ªë ng√†y d·ª± ƒëo√°n:", min_value=1, value=1)
                ma_period = custom_days  # G√°n custom_days cho ma_period n·∫øu ch·ªçn "Kh√°c"
            else:
                # G√°n ma_period d·ª±a tr√™n forecast_period ƒë√£ ch·ªçn
                ma_period = {
                    "1 th√°ng": 1,
                    "6 th√°ng": 6,
                    "12 th√°ng": 12,
                }[forecast_period]

        # N√∫t D·ª± b√°o
        selected_file = f"{selected_symbol}.csv"

        if st.button('D·ª∞ ƒêO√ÅN'):
            # ==== B·∫ÆT ƒê·∫¶U SPINNER ====
            with st.spinner("ƒêang d·ª± ƒëo√°n, vui l√≤ng ch·ªù..."):
                file_path = os.path.join(dataset_dir, selected_file)
                df = pd.read_csv(file_path)
                df['Date'] = pd.to_datetime(df['Date'])
                df.set_index('Date', inplace=True)

                cutoff_date = pd.to_datetime('2022-07-12')
                df_train = df[df.index <= cutoff_date]

                if model_choice == "Simple Moving Average":
                    ma_windows = [int(x.strip()) for x in ma_input.split(",") if x.strip().isdigit() and int(x.strip()) > 0]
                    if not ma_windows:
                        st.warning("Vui l√≤ng nh·∫≠p √≠t nh·∫•t 1 k·ª≥ h·∫°n MA h·ª£p l·ªá.")
                    else:
                        prediction_tables, error_df = calc_ma_prediction_with_real_test(
                            df,
                            ma_windows=ma_windows,
                            forecast_days=forecast_days,
                            train_ratio=0.8
                        )

                        # ƒê·ªçc d·ªØ li·ªáu future th·ª±c t·∫ø t·ª´ yfinance n·∫øu c√≥
                        yf_path = os.path.join("D:/Data Science/yfinance", f"{selected_symbol}.csv")
                        future_actual_dates = []
                        future_actual_close = []
                        if os.path.exists(yf_path):
                            df_yf = pd.read_csv(yf_path)
                            df_yf['Date'] = pd.to_datetime(df_yf['Date'])
                            df_yf = df_yf.sort_values('Date').reset_index(drop=True)
                            future_actual_dates = df_yf['Date'].iloc[:forecast_days]
                            future_actual_close = df_yf['Close'].iloc[:forecast_days]

                        # V·∫Ω bi·ªÉu ƒë·ªì cho t·ª´ng MA
                        for window, preds in prediction_tables.items():
                            fig = go.Figure()

                            fig.add_trace(go.Scatter(
                                x=preds["Train Dates"], y=preds["Train Actual"],
                                name="Train Actual", line=dict(color='#1E90FF')
                            ))
                            fig.add_trace(go.Scatter(
                                x=preds["Test Dates"], y=preds["Test Actual"],
                                name="Test Actual", line=dict(color='black')
                            ))
                            fig.add_trace(go.Scatter(
                                x=preds["Test Dates"], y=preds["Test Predict"],
                                name=f"MA{window} - Test Predict", line=dict(color='red', dash='dash')
                            ))
                            fig.add_trace(go.Scatter(
                                x=preds["Future Dates"], y=preds["Future Predict"],
                                name=f"MA{window} - Future Forecast", line=dict(color='purple', dash='dot')
                            ))

                            # Th√™m Future Actual n·∫øu c√≥
                            if len(future_actual_dates) > 0:
                                fig.add_trace(go.Scatter(
                                    x=future_actual_dates, y=future_actual_close,
                                    name="Future Actual", line=dict(color='green', width=2)
                                ))

                            fig.update_layout(
                                title=f"Bi·ªÉu ƒë·ªì MA{window} - Train/Test/Forecast ({selected_symbol})",
                                xaxis_title="Ng√†y", yaxis_title="Gi√° tr·ªã",
                                plot_bgcolor='white',
                                xaxis=dict(showgrid=False),
                                yaxis=dict(showgrid=False),
                                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                                margin=dict(l=40, r=40, t=60, b=40)
                            )

                            st.plotly_chart(fig, use_container_width=True, key=f"ma_plot_{window}")

                        st.subheader("B·∫£ng ch·ªâ s·ªë l·ªói Train/Test/Future c·ªßa t·ª´ng MA:")
                        st.dataframe(error_df)




                elif model_choice == "Exponential Smoothing By Day":
                    ma_period = int(ma_period)
                    fig, test_pred_df, future_pred_df, error_df = create_adj_close_es_chart_with_prediction(
                        df,
                        smoothing_level=smoothing_level,   # l·∫•y t·ª´ st.slider()
                        train_ratio=0.8,                   # ho·∫∑c b·∫°n t·ª± ch·ªçn t·ªâ l·ªá
                        test_ratio=0.2,
                        forecast_days=ma_period,
                        symbol=selected_symbol,
                        test_folder="D:/Data Science/yfinance/"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    st.caption(f"Tham s·ªë Alpha: {smoothing_level:.2f}")
                    st.subheader("B·∫£ng d·ª± ƒëo√°n Test (so s√°nh gi√° th·∫≠t v√† d·ª± b√°o):")
                    st.dataframe(test_pred_df)
                    if future_pred_df is not None:
                        st.subheader("B·∫£ng d·ª± ƒëo√°n Future:")
                        st.dataframe(future_pred_df)
                    st.subheader("B·∫£ng ch·ªâ s·ªë l·ªói (Train/Test/Future):")
                    st.dataframe(error_df)



                elif model_choice == "Exponential Smoothing By Month":

                    # Call the ES monthly function
                    fig_es_monthly, df_pred_es_monthly, mae, rmse, mape = apply_es_monthly(df, alpha_es, ma_period)

                    # Hi·ªÉn th·ªã ch·ªâ s·ªë l·ªói
                    st.write(f"Alpha: {alpha_es:.2f}%")
                    st.write(f"**Ch·ªâ s·ªë l·ªói (ES):**")
                    st.write(f"  - MAE: {mae:.2f}")
                    st.write(f"  - RMSE: {rmse:.2f}")
                    st.write(f"  - MAPE: {mape:.2f}%")

                    # Display the chart and prediction table
                    st.plotly_chart(fig_es_monthly, use_container_width=True)
                    st.subheader("B·∫£ng d·ª± ƒëo√°n ES (Monthly):")
                    st.dataframe(df_pred_es_monthly)  # Display the prediction DataFrame

                elif model_choice == "Holt By Day":
                    forecast_days = int(ma_period)  # S·ªë ng√†y d·ª± b√°o t∆∞∆°ng lai

                    fig, test_pred_df, future_pred_df, error_df = create_adj_close_holt_chart_with_prediction(
                        df,
                        smoothing_level=alpha,
                        smoothing_slope=beta,
                        train_ratio=0.8,
                        test_ratio=0.2,
                        forecast_days=forecast_days,
                        symbol=selected_symbol,
                        test_folder="D:/Data Science/yfinance/"
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    st.caption(f"Tham s·ªë: Alpha={alpha:.2f}, Beta={beta:.2f}")

                    st.subheader("B·∫£ng d·ª± ƒëo√°n Test (so s√°nh gi√° th·∫≠t v√† d·ª± b√°o):")
                    st.dataframe(test_pred_df)

                    if future_pred_df is not None:
                        st.subheader("B·∫£ng d·ª± ƒëo√°n Future:")
                        st.dataframe(future_pred_df)

                    st.subheader("B·∫£ng ch·ªâ s·ªë l·ªói (Train/Test/Future):")
                    st.dataframe(error_df)



                elif model_choice == "Holt By Month":
                # Call the Holt-Winters monthly function
                    fig_holt_monthly, df_pred_holt_monthly = apply_holt_monthly(
                        df,
                        smoothing_level=alpha_holt,
                        smoothing_trend=beta_holt,
                        forecast_days=ma_period
                    )

                    # Display the chart and prediction table
                    st.plotly_chart(fig_holt_monthly, use_container_width=True)
                    st.subheader("B·∫£ng d·ª± ƒëo√°n Holt (Monthly):")
                    st.dataframe(df_pred_holt_monthly)  

                elif model_choice == "Holt Winter By Day":
                    forecast_days = int(ma_period)

                    fig, test_pred_df, future_pred_df, error_df = create_adj_close_holt_winters_chart_with_prediction(
                        df,
                        alpha=alpha,
                        beta=beta,
                        gamma=gamma,
                        seasonality_periods=seasonality_periods,
                        train_ratio=0.8,
                        test_ratio=0.2,
                        forecast_days=forecast_days,
                        symbol=selected_symbol,
                        test_folder="D:/Data Science/yfinance/"
                    )

                    st.plotly_chart(fig, use_container_width=True)
                    st.caption(f"Tham s·ªë: Alpha={alpha:.2f}, Beta={beta:.2f}, Gamma={gamma:.2f}, Chu k·ª≥ m√πa v·ª•={seasonality_periods}")

                    st.subheader("B·∫£ng d·ª± ƒëo√°n Test (so s√°nh gi√° th·∫≠t v√† d·ª± b√°o):")
                    st.dataframe(test_pred_df)

                    if future_pred_df is not None:
                        st.subheader("B·∫£ng d·ª± ƒëo√°n Future:")
                        st.dataframe(future_pred_df)

                    st.subheader("B·∫£ng ch·ªâ s·ªë l·ªói (Train/Test/Future):")
                    st.dataframe(error_df)


                elif model_choice == "Holt Winter By Month":
                # Call the Holt-Winters monthly function
                    fig_hwm, df_pred_hwm = apply_holt_winters_monthly(
                        df,
                        smoothing_level=alpha_hwm,
                        smoothing_trend=beta_hwm,
                        smoothing_seasonal=gamma_hwm,
                        forecast_days=ma_period
                    )
                    
                    # Display the chart and prediction table
                    st.plotly_chart(fig_hwm, use_container_width=True)
                    st.subheader("B·∫£ng d·ª± ƒëo√°n Holt-Winters (Monthly):")
                    st.dataframe(df_pred_hwm)

           

    elif selected_tab == "Machine Learning":
        from tensorflow.keras.models import load_model
        st.markdown("<h1 style='text-align:center;'>MACHINE LEARNING</h1>", unsafe_allow_html=True)
        st.subheader("HU·∫§N LUY·ªÜN M√î H√åNH")
        st.subheader("Ch·ªçn m√¥ h√¨nh hu·∫•n luy·ªán")
        model_type = st.selectbox("Lo·∫°i m√¥ h√¨nh:", ["LSTM", "GRU"])
        # Ch·ªçn file d·ªØ li·ªáu
        dataset_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dataset")
        selected_symbol = st.text_input("Nh·∫≠p m√£ ch·ª©ng kho√°n", "AAPL").upper().strip()
        selected_file = f"{selected_symbol}.csv"
        file_path = os.path.join(dataset_dir, selected_file)

        # Tham s·ªë
        window_size = st.slider("Sliding window", 10, 1000, 200, 5)
        epochs = st.slider("Epochs", 5, 100, 20)
        batch_size = st.slider("Batch size", 8, 512, 64)

        # ===== N√öT HU·∫§N LUY·ªÜN =====
        if st.button("HU·∫§N LUY·ªÜN"):
            with st.spinner("ƒêang hu·∫•n luy·ªán..."):

                # === ƒê∆∞·ªùng d·∫´n ===
                model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models")
                errors_dir = os.path.join(os.path.dirname(model_dir), "errors")
                os.makedirs(model_dir, exist_ok=True)
                os.makedirs(errors_dir, exist_ok=True)

                # === X√°c ƒë·ªãnh t√™n file m√¥ h√¨nh .h5 c·∫ßn t√¨m ===
                model_file = f"{selected_symbol}_model.h5" if model_type == "LSTM" else f"{selected_symbol}_gru_model.h5"
                model_path = os.path.join(model_dir, model_file)

                # === Ki·ªÉm tra m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i hay ch∆∞a ===
                is_first_time = not os.path.exists(model_path)
                old_mape = None

                # N·∫øu ƒë√£ c√≥ m√¥ h√¨nh, ki·ªÉm tra file l·ªói c≈©
                if not is_first_time:
                    error_suffix = "errors.csv" if model_type == "LSTM" else "gru_errors.csv"
                    error_file = os.path.join(errors_dir, f"{selected_symbol}_{error_suffix}")

                    if os.path.exists(error_file):
                        try:
                            df_errors = pd.read_csv(error_file)
                            if not df_errors.empty:
                                old_mape = df_errors.iloc[-1]['MAPE_Test (%)']
                        except:
                            old_mape = None

                # === Ti·∫øn h√†nh hu·∫•n luy·ªán ===
                if model_type == "LSTM":
                    results = train_lstm_model_from_csv(file_path, window_size, epochs, batch_size)
                else:
                    results = train_gru_model_from_csv(file_path, window_size, epochs, batch_size)

                new_mape = results['mape_test']

                # === Th√¥ng b√°o sau hu·∫•n luy·ªán ===
                st.success(f"ƒê√É HU·∫§N LUY·ªÜN TH√ÄNH C√îNG M√î H√åNH {model_type} CHO M√É `{selected_symbol}`!")
                st.info(f"""
                ### Th√¥ng tin m√¥ h√¨nh:
                - Lo·∫°i m√¥ h√¨nh: `{model_type}`
                - M√£ ch·ª©ng kho√°n: `{selected_symbol}`
                - Sliding Window: `{window_size}`  
                - Epochs: `{epochs}`  
                - Batch Size: `{batch_size}`  
                """)

                # === So s√°nh v√† th√¥ng b√°o c·∫£i ti·∫øn ===
                if is_first_time or old_mape is None:
                    st.success(f"ƒê√¢y l√† m√¥ h√¨nh ƒë·∫ßu ti√™n cho m√£ `{selected_symbol}`. ƒê√£ l∆∞u th√†nh c√¥ng!")
                else:
                    if new_mape < old_mape:
                        st.success(f"M√¥ h√¨nh m·ªõi t·ªët h∆°n m√¥ h√¨nh c≈© (MAPE Test gi·∫£m t·ª´ `{old_mape:.2f}%` xu·ªëng `{new_mape:.2f}%`). ƒê√£ c·∫≠p nh·∫≠t!")
                    elif new_mape > old_mape:
                        st.warning(f"M√¥ h√¨nh m·ªõi c√≥ MAPE Test `{new_mape:.2f}%` cao h∆°n m√¥ h√¨nh c≈© `{old_mape:.2f}%`. ƒêang gi·ªØ m√¥ h√¨nh c≈©.")
                    else:
                        st.info(f"M√¥ h√¨nh m·ªõi c√≥ MAPE Test b·∫±ng m√¥ h√¨nh c≈© ({new_mape:.2f}%).")



                st.subheader("Bi·ªÉu ƒë·ªì Train & Test")

                fig = go.Figure()

                # T·∫≠p Train
                fig.add_trace(go.Scatter(x=results['train_dates'], y=results['y_train_real'].flatten(), name="Gi√° th·ª±c t·∫ø (Train)", line=dict(color="blue")))
                fig.add_trace(go.Scatter(x=results['train_dates'], y=results['y_train_pred'].flatten(), name="D·ª± ƒëo√°n (Train)", line=dict(color="orange", dash="dot")))

                # T·∫≠p Test
                fig.add_trace(go.Scatter(x=results['test_dates'], y=results['y_test_real'].flatten(), name="Gi√° th·ª±c t·∫ø (Test)", line=dict(color="green")))
                fig.add_trace(go.Scatter(x=results['test_dates'], y=results['y_test_pred'].flatten(), name="D·ª± ƒëo√°n (Test)", line=dict(color="red", dash="dash")))

                # T√πy ch·ªânh layout
                fig.update_layout(
                    title=f"D·ª± ƒëo√°n gi√° c·ªï phi·∫øu {selected_symbol} ({model_type})",
                    xaxis_title="Ng√†y",
                    yaxis_title="Gi√° tr·ªã",
                    plot_bgcolor="white",
                    xaxis=dict(showgrid=False),
                    yaxis=dict(showgrid=False),
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    margin=dict(l=40, r=40, t=80, b=40)
                )

                st.plotly_chart(fig, use_container_width=True)


                st.markdown("### ƒê√ÅNH GI√Å M√î H√åNH")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("T·∫≠p Train")
                    st.metric("MAE", f"{results['mae_train']:.2f}")
                    st.metric("RMSE", f"{results['rmse_train']:.2f}")
                    st.metric("MAPE(%)", f"{results['mape_train']:.2f}") 

                with col2:
                    st.markdown("T·∫≠p Test")
                    st.metric("MAE", f"{results['mae_test']:.2f}")  
                    st.metric("RMSE", f"{results['rmse_test']:.2f}")
                    st.metric("MAPE(%)", f"{results['mape_test']:.2f}")

                st.markdown("---")
                st.markdown("### SO S√ÅNH GI√Å TRAIN & TEST V·ªöI TH·ª∞C T·∫æ (15 d√≤ng g·∫ßn nh·∫•t)")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("Train")
                    df_train = pd.DataFrame({
                        "Ng√†y": results['train_dates'].reset_index(drop=True),
                        "Gi√° th·ª±c t·∫ø": results['y_train_real'].flatten(),
                        "D·ª± ƒëo√°n": results['y_train_pred'].flatten()
                    })
                    st.dataframe(df_train.tail(15), use_container_width=True)

                with col2:
                    st.markdown("Test")
                    df_test = pd.DataFrame({
                        "Ng√†y": results['test_dates'].reset_index(drop=True),
                        "Gi√° th·ª±c t·∫ø": results['y_test_real'].flatten(),
                        "D·ª± ƒëo√°n": results['y_test_pred'].flatten()
                    }) 

                    st.dataframe(df_test.tail(15), use_container_width=True)

            # ===== N√öT D·ª∞ ƒêO√ÅN =====
        st.title("D·ª∞ ƒêO√ÅN T·ª™ M√î H√åNH")

        # 1. L·∫•y th∆∞ m·ª•c g·ªëc tuy·ªát ƒë·ªëi
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dataset_dir = os.path.join(base_dir, "dataset")
        model_dir = os.path.join(base_dir, "models")
        os.makedirs(dataset_dir, exist_ok=True)
        os.makedirs(model_dir, exist_ok=True)

                # L·∫•y danh s√°ch m√¥ h√¨nh
        if model_type == "LSTM":
            model_files = [f for f in os.listdir(model_dir) if f.endswith("_model.h5")]
            trained_symbols = [f.replace("_model.h5", "") for f in model_files]
        else:
            model_files = [f for f in os.listdir(model_dir) if f.endswith("_gru_model.h5")]
            trained_symbols = [f.replace("_gru_model.h5", "") for f in model_files]

        # T·∫°o danh s√°ch bi·ªÉu t∆∞·ª£ng chu·∫©n x√°c
        if model_type == "LSTM":
            model_files = [f for f in os.listdir(model_dir) if f.endswith("_model.h5") and not f.endswith("_gru_model.h5")]
            trained_symbols = [f.replace("_model.h5", "") for f in model_files]
        else:
            model_files = [f for f in os.listdir(model_dir) if f.endswith("_gru_model.h5")]
            trained_symbols = [f.replace("_gru_model.h5", "") for f in model_files]

        # N·∫øu kh√¥ng c√≥ m√¥ h√¨nh n√†o
        if not trained_symbols:
            st.warning(f"Kh√¥ng c√≥ m√¥ h√¨nh {model_type} n√†o ƒë√£ hu·∫•n luy·ªán.")
            st.stop()

        selected_symbol = st.selectbox("Ch·ªçn m√£ ch·ª©ng kho√°n ƒë√£ hu·∫•n luy·ªán", trained_symbols)

        dataset_path = os.path.join(dataset_dir, f"{selected_symbol}.csv")

        # ƒê∆∞·ªùng d·∫´n model & metadata
        if model_type == "LSTM":
            model_path = os.path.join(model_dir, f"{selected_symbol}_model.h5")
            scaler_path = os.path.join(model_dir, f"{selected_symbol}_scaler.pkl")
        else:
            model_path = os.path.join(model_dir, f"{selected_symbol}_gru_model.h5")
            scaler_path = os.path.join(model_dir, f"{selected_symbol}_gru_scaler.pkl")

        metadata_path = os.path.join(
            model_dir,
            f"{selected_symbol}_metadata.json" if model_type == "LSTM" else f"{selected_symbol}_gru_metadata.json"
        )

            # 4. Nh·∫≠p tham s·ªë d·ª± ƒëo√°n
        steps = st.number_input("S·ªë ng√†y mu·ªën d·ª± ƒëo√°n", min_value=1, max_value=600, value=22, step=1)


        if st.button("D·ª∞ ƒêO√ÅN"):
            with st.spinner('ƒêang d·ª± ƒëo√°n, vui l√≤ng ch·ªù...'):
                try:
                    # Load model v√† scaler
                    model = load_model(model_path)
                    # ‚úÖ Load ƒë√∫ng window_size ƒë√£ hu·∫•n luy·ªán t·ª´ metadata
                    if os.path.exists(metadata_path):
                        with open(metadata_path, "r") as f:
                            metadata = json.load(f)
                        window_size = metadata.get("window_size", model.input_shape[1])  # <-- l·ªói n·∫øu model ch∆∞a load!
                    else:
                        window_size = model.input_shape[1]  # <-- l·ªói n·∫øu model ch∆∞a load!
                    model = load_model(model_path)  # <-- load model sau!


                    scaler = joblib.load(scaler_path)
                    


                    if not os.path.exists(dataset_path):
                        st.error(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: `{dataset_path}`.")
                        st.stop()

                    df = pd.read_csv(dataset_path)
                    df['Date'] = pd.to_datetime(df['Date'])
                    df = df.sort_values('Date')

                    if len(df) < window_size:
                        st.error(f"D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ d·ª± ƒëo√°n. C·∫ßn √≠t nh·∫•t {window_size} b·∫£n ghi.")
                        st.stop()

                    # --------- D·ª± ƒëo√°n tr√™n t·∫≠p Train ---------
                    data = df['Close'].values.reshape(-1, 1)
                    scaled = scaler.transform(data)
                    if len(scaled) >= window_size:
                        X_all, y_all = create_dataset(scaled, window_size)
                        X_all = X_all.reshape(-1, window_size, 1)
                        train_preds_scaled = model.predict(X_all, verbose=0)
                        train_preds = scaler.inverse_transform(train_preds_scaled).flatten()
                        train_pred_dates = df['Date'].iloc[window_size:window_size + len(train_preds)]



                    # --------- D·ª± ƒëo√°n t∆∞∆°ng lai ---------
                    # D·ª± ƒëo√°n t∆∞∆°ng lai
                    if model_type == "LSTM":
                        future_preds = predict_future(df, scaler, window_size=window_size, steps=steps, selected_symbol=selected_symbol)
                    else:
                        future_preds = predict_future_gru(df, scaler, window_size=window_size, steps=steps, selected_symbol=selected_symbol)


                    # T·∫°o ƒë√∫ng s·ªë l∆∞·ª£ng ng√†y giao d·ªãch ti·∫øp theo (b·ªè cu·ªëi tu·∫ßn)
                    future_dates = []
                    curr_date = df['Date'].iloc[-1] + pd.Timedelta(days=1)
                    while len(future_dates) < steps:
                        if curr_date.weekday() < 5:  # th·ª© 2‚Äì6
                            future_dates.append(curr_date)
                        curr_date += pd.Timedelta(days=1)

                    # C·∫Øt n·∫øu kh√¥ng kh·ªõp ƒë·ªô d√†i (ƒë·ªÉ tr√°nh l·ªói)
                    min_len = min(len(future_dates), len(future_preds))
                    future_dates = future_dates[:min_len]
                    future_preds = future_preds[:min_len]

                    # T·∫°o b·∫£ng d·ª± ƒëo√°n
                    df_pred = pd.DataFrame({'Ng√†y': future_dates, 'Gi√° d·ª± ƒëo√°n': future_preds})

                    # ƒê·ªçc d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ th∆∞ m·ª•c yfinance
                    try:
                        real_path = os.path.join(os.path.dirname(__file__), "yfinance", f"{selected_symbol}.csv")
                        data_real = pd.read_csv(real_path)

                        # T√¨m v√† chu·∫©n h√≥a c·ªôt ng√†y
                        for col in ['Date', 'Ng√†y', 'Unnamed: 0']:
                            if col in data_real.columns:
                                data_real = data_real.rename(columns={col: 'Ng√†y'})
                                break
                        data_real['Ng√†y'] = pd.to_datetime(data_real['Ng√†y'])

                        # ƒê·ªïi t√™n c·ªôt gi√°
                        if 'Close' in data_real.columns:
                            data_real = data_real[['Ng√†y', 'Close']].rename(columns={'Close': 'Gi√° th·ª±c t·∫ø'})

                            # N·ªëi v√† hi·ªÉn th·ªã b·∫£ng
                            merged = pd.merge(df_pred, data_real, on='Ng√†y', how='left')
                            st.markdown("### D·ª∞ ƒêO√ÅN V√Ä TH·ª∞C T·∫æ")
                            st.dataframe(merged, use_container_width=True)

                            # T√≠nh l·ªói n·∫øu ƒë·ªß d·ªØ li·ªáu
                            valid = merged.dropna()
                        else:
                            st.warning("Kh√¥ng c√≥ c·ªôt 'Close' trong d·ªØ li·ªáu th·ª±c t·∫ø.")
                    except Exception as e:
                        st.error(f"L·ªói khi ƒë·ªçc d·ªØ li·ªáu th·ª±c t·∫ø: {e}")


  


                   # ======= ƒê·ªçc d·ªØ li·ªáu th·ª±c t·∫ø t∆∞∆°ng lai t·ª´ yfinance =======
                    future_real_path = os.path.join(os.path.dirname(__file__), "yfinance", f"{selected_symbol}.csv")
                    df_real_future = None

                    if os.path.exists(future_real_path):
                        try:
                            df_real_future = pd.read_csv(future_real_path)
                            for col in ['Date', 'Ng√†y', 'Unnamed: 0']:
                                if col in df_real_future.columns:
                                    df_real_future.rename(columns={col: 'Ng√†y'}, inplace=True)
                                    break
                            df_real_future['Ng√†y'] = pd.to_datetime(df_real_future['Ng√†y'])

                            if 'Close' in df_real_future.columns:
                                df_real_future = df_real_future[['Ng√†y', 'Close']].rename(columns={'Close': 'Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'})
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc gi√° th·ª±c t·∫ø t∆∞∆°ng lai t·ª´ yfinance: {e}")


                    # ======= V·∫Ω bi·ªÉu ƒë·ªì =======
                    st.subheader("BI·ªÇU ƒê·ªí D·ª∞ ƒêO√ÅN")

                    fig = go.Figure()

                    # 1. Gi√° th·ª±c t·∫ø l·ªãch s·ª≠
                    fig.add_trace(go.Scatter(
                        x=df['Date'], y=df['Close'],
                        mode='lines', name='Gi√° th·ª±c t·∫ø',
                        line=dict(color='green')
                    ))

                    # 2. D·ª± ƒëo√°n tr√™n t·∫≠p Train (n·∫øu c√≥)
                    if 'train_preds' in locals() and train_preds is not None:
                        train_pred_dates = df['Date'].iloc[window_size:window_size + len(train_preds)]
                        fig.add_trace(go.Scatter(
                            x=train_pred_dates, y=train_preds,
                            mode='lines', name='D·ª± ƒëo√°n (Train)',
                            line=dict(color='orange')
                        ))

                    # 3. D·ª± ƒëo√°n t∆∞∆°ng lai
                    fig.add_trace(go.Scatter(
                        x=df_pred['Ng√†y'], y=df_pred['Gi√° d·ª± ƒëo√°n'],
                        mode='lines', name='D·ª± ƒëo√°n t∆∞∆°ng lai',
                        line=dict(color='red', dash='dot')
                    ))

                    # 4. Gi√° th·ª±c t·∫ø t∆∞∆°ng lai t·ª´ yfinance (n·∫øu c√≥)
                    if df_real_future is not None and 'Gi√° th·ª±c t·∫ø t∆∞∆°ng lai' in df_real_future.columns:
                        df_merge_plot = pd.merge(df_pred[['Ng√†y']], df_real_future, on='Ng√†y', how='left')
                        if df_merge_plot['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'].notna().any():
                            fig.add_trace(go.Scatter(
                                x=df_merge_plot['Ng√†y'], y=df_merge_plot['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'],
                                mode='lines', name='Gi√° th·ª±c t·∫ø t∆∞∆°ng lai',
                                line=dict(color='blue')
                            ))

                    # Layout chung
                    fig.update_layout(
                        title=f"D·ª± ƒëo√°n gi√° c·ªï phi·∫øu {selected_symbol} ({model_type})",
                        xaxis_title="Ng√†y",
                        yaxis_title="Gi√° c·ªï phi·∫øu",
                        plot_bgcolor='white',
                        xaxis=dict(showgrid=False),
                        yaxis=dict(showgrid=False),
                        height=600,
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                        margin=dict(l=40, r=40, t=80, b=40)
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    # ======= T√≠nh l·ªói n·∫øu c√≥ d·ªØ li·ªáu th·ª±c t·∫ø t∆∞∆°ng lai =======
                    if df_real_future is not None and 'Gi√° th·ª±c t·∫ø t∆∞∆°ng lai' in df_real_future.columns:
                        df_eval = pd.merge(df_pred, df_real_future, on='Ng√†y', how='inner').dropna()

                        if not df_eval.empty:

                            mae = mean_absolute_error(df_eval['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'], df_eval['Gi√° d·ª± ƒëo√°n'])
                            rmse = np.sqrt(mean_squared_error(df_eval['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'], df_eval['Gi√° d·ª± ƒëo√°n']))
                            mape = np.mean(np.abs((df_eval['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'] - df_eval['Gi√° d·ª± ƒëo√°n']) / df_eval['Gi√° th·ª±c t·∫ø t∆∞∆°ng lai'])) * 100

                            st.markdown("### B·∫¢NG CH·ªà S·ªê L·ªñI")
                            df_errors = pd.DataFrame({
                                "MAE": [f"{mae:.2f}"],
                                "RMSE": [f"{rmse:.2f}"],
                                "MAPE (%)": [f"{mape:.2f}"]
                            })
                            st.dataframe(df_errors, use_container_width=True)
                        else:
                            st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh sai s·ªë d·ª± ƒëo√°n t∆∞∆°ng lai.")

                except Exception as e:
                    import traceback
                    st.error(f"‚ùå L·ªói khi d·ª± ƒëo√°n: {e}\n\nChi ti·∫øt l·ªói:\n{traceback.format_exc()}")







    elif selected_tab == "Optimized ML":
        from tensorflow.keras.models import load_model
        st.markdown("<h1 style='text-align:center;'>OPTIMIZED MACHINE LEARNING MODEL</h1>", unsafe_allow_html=True)
        st.subheader("HU·∫§N LUY·ªÜN M√î H√åNH")
        st.subheader("Ch·ªçn m√¥ h√¨nh hu·∫•n luy·ªán")
        model_type = st.selectbox("Lo·∫°i m√¥ h√¨nh:", ["Optimized LSTM", "Optimized GRU"])
        # ======= Ch·ªçn lo·∫°i m√¥ h√¨nh n·ªÅn t·∫£ng v√† c√≥ d√πng 2 nh√°nh hay kh√¥ng =======
        model_type_simple = "LSTM" if model_type == "Optimized LSTM" else "GRU"
        branch_model = st.checkbox("S·ª≠ d·ª•ng m√¥ h√¨nh k·∫øt h·ª£p (2 nh√°nh)", value=False)
        # Ch·ªçn file d·ªØ li·ªáu
        dataset_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dataset")
        selected_symbol = st.text_input("Nh·∫≠p m√£ ch·ª©ng kho√°n", "AAPL").upper().strip()
        selected_file = f"{selected_symbol}.csv"
        file_path = os.path.join(dataset_dir, selected_file)

        # Tham s·ªë
        window_size = st.slider("Sliding window", 10, 1000, 200, 5)
        epochs = st.slider("Epochs", 5, 100, 20)
        batch_size = st.slider("Batch size", 8, 512, 64)

        # ===== N√öT HU·∫§N LUY·ªÜN =====
        if st.button("HU·∫§N LUY·ªÜN"):
            with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh t·ªëi ∆∞u, c√≥ th·ªÉ s·∫Ω m·∫•t nhi·ªÅu th·ªùi gian c·ªßa b·∫°n h∆°n..."):

                # === Th∆∞ m·ª•c l∆∞u ===
                model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models_optimal")
                errors_dir = os.path.join(os.path.dirname(model_dir), "errors")
                os.makedirs(model_dir, exist_ok=True)
                os.makedirs(errors_dir, exist_ok=True)

                # === X√°c ƒë·ªãnh t√™n file theo lo·∫°i m√¥ h√¨nh ===
                model_type_simple = "lstm" if "LSTM" in model_type.upper() else "gru"
    
                if branch_model:
                    suffix_model = f"{model_type_simple}_dual_branch_model"
                    suffix_error = f"{model_type_simple}_dual_branch_errors.csv"
                else:
                    suffix_model = f"{model_type_simple}_model"
                    suffix_error = f"{model_type_simple}_errors.csv"

                model_file = f"{selected_symbol}_{suffix_model}.h5"
                model_path = os.path.join(model_dir, model_file)

                error_file = os.path.join(errors_dir, f"{selected_symbol}_{suffix_error}")

                # === Ki·ªÉm tra m√¥ h√¨nh c≈© ===
                is_first_time = not os.path.exists(model_path)
                old_mape = None

                if not is_first_time and os.path.exists(error_file):
                    try:
                        df_errors = pd.read_csv(error_file)
                        if not df_errors.empty:
                            old_mape = df_errors.iloc[-1]['MAPE_Test (%)']
                    except:
                        old_mape = None

                # === HU·∫§N LUY·ªÜN ===
                try:
                    if branch_model:
                        results = train_dual_branch_model(
                            file_path=file_path,
                            model_type=model_type,
                            window_size=window_size,
                            epochs=epochs,
                            batch_size=batch_size
                        )
                    else:
                        results = train_model_optimized(
                            file_path=file_path,
                            window_size=window_size,
                            epochs=epochs,
                            batch_size=batch_size,
                            model_type=model_type_simple,
                            branch_model=False
                        )
                except Exception as e:
                    st.error(f"L·ªói khi hu·∫•n luy·ªán: {e}")
                    st.stop()

                new_mape = results['mape_test']

                # === Th√¥ng b√°o sau hu·∫•n luy·ªán ===
                if branch_model:
                    branch_type = "M√¥ h√¨nh **2 nh√°nh (dual-branch)**"
                else:
                    branch_type = "M√¥ h√¨nh **1 nh√°nh (single-branch)**"

                st.info(f"""
                ### Th√¥ng tin m√¥ h√¨nh:
                - Lo·∫°i m√¥ h√¨nh: `{model_type}`
                - Ki·ªÉu nh√°nh: {branch_type}
                - M√£ ch·ª©ng kho√°n: `{selected_symbol}`
                - Sliding Window: `{window_size}`
                - Epochs: `{epochs}`
                - Batch Size: `{batch_size}`
                """)


                # --- CHU·∫®N B·ªä TH∆Ø M·ª§C & DANH S√ÅCH MODEL ---
                base_dir = os.path.dirname(os.path.abspath(__file__))
                dataset_dir = os.path.join(base_dir, "dataset")
                model_dir = os.path.join(base_dir, "models_optimal")
                os.makedirs(dataset_dir, exist_ok=True)
                os.makedirs(model_dir, exist_ok=True)

                # ·ªû d∆∞·ªõi, kh√¥ng c·∫ßn selectbox n·ªØa, ch·ªâ c·∫ßn:
                suffix_model = "_lstm_model.h5" if model_type == "Optimized LSTM" else "_gru_model.h5"
                suffix_dual = "_lstm_dual_branch_model.h5" if model_type == "Optimized LSTM" else "_gru_dual_branch_model.h5"

                normal_model_path = os.path.join(model_dir, f"{selected_symbol}{suffix_model}")
                dual_model_path = os.path.join(model_dir, f"{selected_symbol}{suffix_dual}")

                if os.path.exists(dual_model_path):
                    is_dual_branch = True
                elif os.path.exists(normal_model_path):
                    is_dual_branch = False
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y model cho m√£ n√†y.")
                    st.stop()

                # X√°c ƒë·ªãnh lo·∫°i m√¥ h√¨nh text ƒë·ªÉ hi·ªÉn th·ªã
                model_branch_text = "hai nh√°nh (dual branch)" if branch_model else "m·ªôt nh√°nh (single branch)"


                # === ƒê√°nh gi√° c·∫£i ti·∫øn MAPE ===
                if is_first_time or old_mape is None:
                    st.success(
                        f"ƒê√¢y l√† m√¥ h√¨nh ƒë·∫ßu ti√™n cho m√£ `{selected_symbol}`.\n"
                        f"Lo·∫°i m√¥ h√¨nh: **{model_type} ‚Äì {model_branch_text}**. ƒê√£ l∆∞u th√†nh c√¥ng!"
                    )
                else:
                    if new_mape < old_mape:
                        st.success(
                            f"M√¥ h√¨nh m·ªõi (**{model_type} ‚Äì {model_branch_text}**) t·ªët h∆°n m√¥ h√¨nh c≈© "
                            f"(MAPE Test gi·∫£m t·ª´ `{old_mape:.2f}%` xu·ªëng `{new_mape:.2f}%`). ƒê√£ c·∫≠p nh·∫≠t!"
                        )
                    elif new_mape > old_mape:
                        st.warning(
                            f"M√¥ h√¨nh m·ªõi (**{model_type} ‚Äì {model_branch_text}**) c√≥ MAPE Test `{new_mape:.2f}%` "
                            f"cao h∆°n m√¥ h√¨nh c≈© `{old_mape:.2f}%`. ƒêang gi·ªØ m√¥ h√¨nh c≈©."
                        )
                    else:
                        st.info(
                            f"M√¥ h√¨nh m·ªõi (**{model_type} ‚Äì {model_branch_text}**) c√≥ MAPE Test b·∫±ng m√¥ h√¨nh c≈© "
                            f"({new_mape:.2f}%)."
                        )


                


                st.subheader("BI·ªÇU ƒê·ªí TRAIN & TEST")
                # --- ƒê·ªåC METADATA L·∫§Y window_size ƒê√öNG C·ª¶A MODEL ---
                meta_ext = (
                    f"{model_type.lower().split()[-1]}_dual_branch_metadata.json"
                    if is_dual_branch else
                    f"{model_type.lower().split()[-1]}_metadata.json"
                )
                metadata_path = os.path.join(model_dir, f"{selected_symbol}_{meta_ext}")
                window_size = 60  # fallback default



                # 1. X√°c ƒë·ªãnh file model & metadata
                model_type_simple = "lstm" if "LSTM" in model_type.upper() else "gru"
                if is_dual_branch:
                    model_suffix = f"_{model_type_simple}_dual_branch_model.h5"
                    metadata_name = f"{selected_symbol}_{model_type_simple}_dual_branch_metadata.json"
                else:
                    model_suffix = f"_{model_type_simple}_model.h5"
                    metadata_name = f"{selected_symbol}_{model_type_simple}_metadata.json"

                model_path = os.path.join(model_dir, f"{selected_symbol}{model_suffix}")
                metadata_path = os.path.join(model_dir, metadata_name)

                # --- **LU√îN LOAD MODEL TR∆Ø·ªöC** ---
                model = load_model(model_path)   # <- PH·∫¢I ƒê·ª®NG TR∆Ø·ªöC!

                # --- SAU ƒê√ì m·ªõi l·∫•y window_size ---
                if os.path.exists(metadata_path):
                    with open(metadata_path, "r") as f:
                        metadata = json.load(f)
                    window_size = metadata.get("window_size", model.input_shape[1])  # ƒê∆∞·ª£c ph√©p d√πng model.input_shape[1] v√¨ ƒë√£ load r·ªìi
                else:
                    window_size = model.input_shape[1]


                # 1. ƒê·ªçc d·ªØ li·ªáu
                csv_path = os.path.join("dataset", f"{selected_symbol}.csv")
                if not os.path.exists(csv_path):
                    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {csv_path}")
                    st.stop()
                df = pd.read_csv(csv_path)
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date')

                # 1. Load scaler tr∆∞·ªõc!
                if is_dual_branch:
                    scaler_close_name = f"{selected_symbol}_{model_type_simple}_dual_scaler_close.pkl"
                    scaler_multi_name = f"{selected_symbol}_{model_type_simple}_dual_scaler_multi.pkl"
                    scaler_close_path = os.path.join("models_optimal", scaler_close_name)
                    scaler_multi_path = os.path.join("models_optimal", scaler_multi_name)
                    if not os.path.exists(scaler_close_path) or not os.path.exists(scaler_multi_path):
                        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y scaler dual cho m√¥ h√¨nh: {scaler_close_path} ho·∫∑c {scaler_multi_path}")
                        st.stop()
                    scaler_close = joblib.load(scaler_close_path)
                    scaler_multi = joblib.load(scaler_multi_path)
                else:
                    scaler_name = f"{selected_symbol}_{model_type_simple}_scaler.pkl"
                    scaler_path = os.path.join("models_optimal", scaler_name)
                    if not os.path.exists(scaler_path):
                        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y scaler cho m√¥ h√¨nh: {scaler_path}")
                        st.stop()
                    scaler = joblib.load(scaler_path)

                if is_dual_branch:
                    df_feature = add_technical_indicators(df.copy())
                    df_feature = df_feature.dropna().reset_index(drop=True)
                    feature_cols = [
                        'close_lag1',
                        'close_lag5',
                        'close_lag10',
                        'log_return'
                    ]
                    multi_data = df_feature[feature_cols].values
                    close_data = df_feature['Close'].values.reshape(-1, 1)


                    scaled_multi = scaler_multi.transform(multi_data)
                    scaled_close = scaler_close.transform(close_data)

                    if len(scaled_multi) >= window_size and len(scaled_close) >= window_size:
                        X_multi_all = np.array([scaled_multi[i:i + window_size] for i in range(len(scaled_multi) - window_size)])
                        X_close_all = np.array([scaled_close[i:i + window_size] for i in range(len(scaled_close) - window_size)])
                        X_close_all = X_close_all.reshape(-1, window_size, 1)

                        model_suffix = f"{model_type_simple}_dual_branch_model"
                        model_path = os.path.join(model_dir, f"{selected_symbol}_{model_suffix}.h5")
                        model = load_model(model_path)
                        train_preds_scaled = model.predict([X_multi_all, X_close_all], verbose=0)
                        train_preds = scaler_close.inverse_transform(train_preds_scaled).flatten()
                        # L·∫•y Date t·ª´ df_feature (v√¨ ƒë√£ dropna ƒë·∫ßu chu·ªói!)
                        train_pred_dates = df_feature['Date'].iloc[window_size:window_size + len(train_preds)]
                    else:
                        train_preds = None
                        train_pred_dates = None

                else:
                    df_close_only = df[['Date', 'Close']].copy()
                    data = df_close_only['Close'].values.reshape(-1, 1)
                    scaled_data = scaler.transform(data)
                    if len(scaled_data) >= window_size:
                        X_all = np.array([scaled_data[i:i + window_size] for i in range(len(scaled_data) - window_size)])
                        X_all = X_all.reshape(-1, window_size, 1)
                        model_suffix = f"{model_type_simple}_model"
                        model_path = os.path.join(model_dir, f"{selected_symbol}_{model_suffix}.h5")
                        model = load_model(model_path)
                        train_preds_scaled = model.predict(X_all, verbose=0)
                        train_preds = scaler.inverse_transform(train_preds_scaled).flatten()
                        train_pred_dates = df_close_only['Date'].iloc[window_size:window_size + len(train_preds)]
                    else:
                        train_preds = None
                        train_pred_dates = None



                fig = go.Figure()
                # V·∫Ω t·∫≠p Train theo th·ªùi gian
                fig.add_trace(go.Scatter(
                    x=results['train_dates'], y=results['y_train_real'].flatten(),
                    name="Gi√° th·ª±c t·∫ø (Train)", line=dict(color="blue")
                ))
                fig.add_trace(go.Scatter(
                    x=results['train_dates'], y=results['y_train_pred'].flatten(),
                    name="D·ª± ƒëo√°n (Train)", line=dict(color="orange")
                ))

                # V·∫Ω t·∫≠p Test theo th·ªùi gian
                fig.add_trace(go.Scatter(
                    x=results['test_dates'], y=results['y_test_real'].flatten(),
                    name="Gi√° th·ª±c t·∫ø (Test)", line=dict(color="green"), mode="lines"
                ))
                fig.add_trace(go.Scatter(
                    x=results['test_dates'], y=results['y_test_pred'].flatten(),
                    name="D·ª± ƒëo√°n (Test)", line=dict(color="red"), mode="lines"
                ))
                # T√πy ch·ªânh layout
                fig.update_layout(
                    title=f"D·ª± ƒëo√°n gi√° c·ªï phi·∫øu {selected_symbol} ({model_type})",
                    xaxis_title="Ng√†y",
                    yaxis_title="Gi√° tr·ªã",
                    plot_bgcolor="white",
                    xaxis=dict(showgrid=False),
                    yaxis=dict(showgrid=False),
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                st.plotly_chart(fig, use_container_width=True)

                st.markdown("### ƒê√ÅNH GI√Å M√î H√åNH")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("Train")
                    st.metric("MAE", f"{results['mae_train']:.2f}")
                    st.metric("RMSE", f"{results['rmse_train']:.2f}")
                    st.metric("MAPE(%)", f"{results['mape_train']:.2f}") 

                with col2:
                    st.markdown("Test")
                    st.metric("MAE", f"{results['mae_test']:.2f}")  
                    st.metric("RMSE", f"{results['rmse_test']:.2f}")
                    st.metric("MAPE(%)", f"{results['mape_test']:.2f}")

                st.markdown("---")
                st.markdown("### SO S√ÅNH GI√Å TRAIN & TEST V·ªöI TH·ª∞C T·∫æ (15 d√≤ng g·∫ßn nh·∫•t)")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("Train")
                    df_train = pd.DataFrame({
                        "Ng√†y": results['train_dates'].reset_index(drop=True),
                        "Gi√° th·ª±c t·∫ø": results['y_train_real'].flatten(),
                        "D·ª± ƒëo√°n": results['y_train_pred'].flatten()
                    })
                    st.dataframe(df_train.tail(15), use_container_width=True)

                with col2:
                    st.markdown("Test")
                    df_test = pd.DataFrame({
                        "Ng√†y": results['test_dates'].reset_index(drop=True),
                        "Gi√° th·ª±c t·∫ø": results['y_test_real'].flatten(),
                        "D·ª± ƒëo√°n": results['y_test_pred'].flatten()
                    }) 

                    st.dataframe(df_test.tail(15), use_container_width=True)


        # ==== D·ª∞ ƒêO√ÅN T·ª™ M√î H√åNH ====
        st.title("D·ª∞ ƒêO√ÅN T·ª™ M√î H√åNH")

        # 1. Setup th∆∞ m·ª•c
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dataset_dir = os.path.join(base_dir, "dataset")
        model_dir = os.path.join(base_dir, "models_optimal")
        os.makedirs(dataset_dir, exist_ok=True)
        os.makedirs(model_dir, exist_ok=True)

        # 2. L·∫•y danh s√°ch model (single/dual, lstm/gru)
        suffix_model = "_lstm_model.h5" if model_type == "Optimized LSTM" else "_gru_model.h5"
        suffix_dual = "_lstm_dual_branch_model.h5" if model_type == "Optimized LSTM" else "_gru_dual_branch_model.h5"

        all_model_files = os.listdir(model_dir)
        normal_models = [f for f in all_model_files if f.endswith(suffix_model)]
        dual_models = [f for f in all_model_files if f.endswith(suffix_dual)]

        model_map = {}
        display_models = []
        for f in normal_models:
            symbol = f.replace(suffix_model, "")
            label = f"{symbol} (Single)"
            display_models.append(label)
            model_map[label] = {"symbol": symbol, "is_dual": False}
        for f in dual_models:
            symbol = f.replace(suffix_dual, "")
            label = f"{symbol} (Dual)"
            display_models.append(label)
            model_map[label] = {"symbol": symbol, "is_dual": True}
        if not display_models:
            st.warning(f"Kh√¥ng c√≥ m√¥ h√¨nh {model_type} n√†o ƒë√£ hu·∫•n luy·ªán.")
            st.stop()

        # 3. Ch·ªçn m√£ CK & ki·ªÉu model
        selected_display = st.selectbox("Ch·ªçn m√£ ch·ª©ng kho√°n ", display_models)
        selected_symbol = model_map[selected_display]["symbol"]
        is_dual_branch = model_map[selected_display]["is_dual"]

        # 1. X√°c ƒë·ªãnh t√™n file model & metadata d·ª±a theo is_dual_branch
        # 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n model & metadata
        # ƒê·∫ßu ti√™n: x√°c ƒë·ªãnh file model v√† metadata
        model_type_simple = "lstm" if "LSTM" in model_type.upper() else "gru"
        if is_dual_branch:
            model_suffix = f"_{model_type_simple}_dual_branch_model.h5"
            metadata_name = f"{selected_symbol}_{model_type_simple}_dual_branch_metadata.json"
        else:
            model_suffix = f"_{model_type_simple}_model.h5"
            metadata_name = f"{selected_symbol}_{model_type_simple}_metadata.json"

        model_path = os.path.join(model_dir, f"{selected_symbol}{model_suffix}")
        metadata_path = os.path.join(model_dir, metadata_name)

        # TI·∫æP THEO: LOAD MODEL ·ªû ƒê√ÇY!
        model = load_model(model_path)   # <- D√íNG N√ÄY LU√îN PH·∫¢I ƒê·ª®NG TR∆Ø·ªöC!

        # SAU ƒê√ì m·ªõi l·∫•y window_size
        if os.path.exists(metadata_path):
            with open(metadata_path, "r") as f:
                metadata = json.load(f)
            window_size = metadata.get("window_size", model.input_shape[1])  # L√∫c n√†y model ƒë√£ c√≥ r·ªìi
        else:
            window_size = model.input_shape[1]







        # 6. Load scaler
        if is_dual_branch:
            scaler_close_name = f"{selected_symbol}_{model_type_simple}_dual_scaler_close.pkl"
            scaler_multi_name = f"{selected_symbol}_{model_type_simple}_dual_scaler_multi.pkl"
            scaler_close_path = os.path.join(model_dir, scaler_close_name)
            scaler_multi_path = os.path.join(model_dir, scaler_multi_name)
            if not os.path.exists(scaler_close_path) or not os.path.exists(scaler_multi_path):
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y scaler dual cho m√¥ h√¨nh: {scaler_close_path} ho·∫∑c {scaler_multi_path}")
                st.stop()
            scaler_close = joblib.load(scaler_close_path)
            scaler_multi = joblib.load(scaler_multi_path)
        else:
            scaler_name = f"{selected_symbol}_{model_type_simple}_scaler.pkl"
            scaler_path = os.path.join(model_dir, scaler_name)
            if not os.path.exists(scaler_path):
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y scaler cho m√¥ h√¨nh: {scaler_path}")
                st.stop()
            scaler = joblib.load(scaler_path)

        # 7. Load dataset
        dataset_path = os.path.join(dataset_dir, f"{selected_symbol}.csv")
        if not os.path.exists(dataset_path):
            st.error(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu: `{dataset_path}`.")
            st.stop()

        df = pd.read_csv(dataset_path)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        if len(df) < window_size:
            st.error(f"D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ d·ª± ƒëo√°n. C·∫ßn {window_size} b·∫£n ghi.")
            st.stop()

        steps = st.number_input("S·ªë ng√†y mu·ªën d·ª± ƒëo√°n", min_value=1, max_value=365, value=22, step=1)

        df_real_future = None
        df_pred = None

        if st.button("D·ª∞ ƒêO√ÅN"):
            with st.spinner('ƒêang d·ª± ƒëo√°n, vui l√≤ng ch·ªù...'):
                try:



                    # ==== 1. D·ª± ƒëo√°n t∆∞∆°ng lai ====
                    future_preds = predict_goodnine(
                        df=df,
                        scaler=scaler_close if is_dual_branch else scaler,
                        window_size=window_size,
                        steps=steps,
                        selected_symbol=selected_symbol,
                        model_type=model_type,
                        is_dual_branch=is_dual_branch
                    )

                    # 3. KI·ªÇM TRA GI√Å TR·ªä D·ª∞ ƒêO√ÅN ƒê·∫¶U TI√äN
                    st.write("Gi√° tr·ªã ƒë·∫ßu ti√™n d·ª± ƒëo√°n t∆∞∆°ng lai:", future_preds[0])
                    st.write("Gi√° cu·ªëi c√πng c·ªßa th·ª±c t·∫ø:", df['Close'].iloc[-1])

                    future_dates = []
                    # Ng√†y b·∫Øt ƒë·∫ßu d·ª± b√°o l√† ng√†y cu·ªëi c√πng trong dataset + 1
                    future_dates = []
                    curr_date = df['Date'].max() + pd.Timedelta(days=1)
                    while len(future_dates) < steps:
                        if curr_date.weekday() < 5:  # Ch·ªâ th·ª© 2-6
                            future_dates.append(curr_date)
                        curr_date += pd.Timedelta(days=1)
                    df_pred = pd.DataFrame({"Ng√†y": future_dates, "Gi√° d·ª± ƒëo√°n": future_preds})


                    train_preds = None
                    train_pred_dates = None
                    if is_dual_branch:
                        df_feature = add_technical_indicators(df.copy())
                        df_feature = df_feature.dropna().reset_index(drop=True)
                        feature_cols = [
                            'close_lag1',
                            'close_lag5',
                            'close_lag10',
                            'log_return'
                        ]
                        multi_data = df_feature[feature_cols].values
                        close_data = df_feature['Close'].values.reshape(-1, 1)
                        scaled_multi = scaler_multi.transform(multi_data)
                        scaled_close = scaler_close.transform(close_data)
                        if len(scaled_multi) >= window_size and len(scaled_close) >= window_size:
                            X_multi_all, y_all = create_dataset_multi(scaled_multi, scaled_close, window_size)
                            X_close_all, _ = create_dataset_multi(scaled_close, scaled_close, window_size)
                            X_close_all = X_close_all.reshape(-1, window_size, 1)
                            train_preds_scaled = model.predict([X_multi_all, X_close_all], verbose=0)
                            train_preds = scaler_close.inverse_transform(train_preds_scaled).flatten()
                            train_pred_dates = df_feature['Date'].iloc[window_size:window_size + len(train_preds)]
                    else:
                        data = df['Close'].values.reshape(-1, 1)
                        scaled = scaler.transform(data)
                        if len(scaled) >= window_size:
                               X_all, y_all = create_dataset_uni(scaled, window_size)
                        X_all = X_all.reshape(-1, window_size, 1)
                        train_preds_scaled = model.predict(X_all, verbose=0)
                        train_preds = scaler.inverse_transform(train_preds_scaled).flatten()
                        train_pred_dates = df['Date'].iloc[window_size:window_size + len(train_preds)]


                    # ==== 3. ƒê·ªçc d·ªØ li·ªáu th·ª±c t·∫ø t∆∞∆°ng lai (n·∫øu c√≥) ====
                    df_real_future = None
                    future_real_path = os.path.join(base_dir, "yfinance", f"{selected_symbol}.csv")
                    if os.path.exists(future_real_path):
                        df_real_future = pd.read_csv(future_real_path)
                        for col in ['Date', 'Ng√†y', 'Unnamed: 0']:
                            if col in df_real_future.columns:
                                df_real_future.rename(columns={col: 'Ng√†y'}, inplace=True)
                                break
                        df_real_future['Ng√†y'] = pd.to_datetime(df_real_future['Ng√†y'])
                        if 'Close' in df_real_future.columns:
                            df_real_future = df_real_future[['Ng√†y', 'Close']].rename(columns={'Close': 'Gi√° th·ª±c t·∫ø'})

                    # ==== 4. Hi·ªÉn th·ªã b·∫£ng d·ª± ƒëo√°n ====
                    if df_real_future is not None and 'Gi√° th·ª±c t·∫ø' in df_real_future.columns:
                        df_eval = pd.merge(df_pred, df_real_future, on='Ng√†y', how='left')
                        st.markdown("### B·∫¢NG D·ª∞ ƒêO√ÅN V√Ä GI√Å TH·ª∞C T·∫æ")
                        st.dataframe(df_eval, use_container_width=True)
                    else:
                        st.markdown("### B·∫¢NG D·ª∞ ƒêO√ÅN")
                        st.dataframe(df_pred, use_container_width=True)

                    # --- L·∫§Y D·ª∞ ƒêO√ÅN TO√ÄN B·ªò NHANH ---
                    if is_dual_branch:
                        X_multi_all = np.array([scaled_multi[i:i + window_size] for i in range(len(scaled_multi) - window_size)])
                        X_close_all = np.array([scaled_close[i:i + window_size] for i in range(len(scaled_close) - window_size)])
                        X_close_all = X_close_all.reshape(-1, window_size, 1)
                        full_preds_scaled = model.predict([X_multi_all, X_close_all], verbose=0)
                        full_preds = scaler_close.inverse_transform(full_preds_scaled).flatten()
                        full_pred_dates = df_feature['Date'].iloc[window_size:window_size + len(full_preds)]
                    else:
                        X_all = np.array([scaled[i:i + window_size] for i in range(len(scaled) - window_size)])
                        X_all = X_all.reshape(-1, window_size, 1)
                        full_preds_scaled = model.predict(X_all, verbose=0)
                        full_preds = scaler.inverse_transform(full_preds_scaled).flatten()
                        full_pred_dates = df['Date'].iloc[window_size:window_size + len(full_preds)]




                    def safe_list(x):
                        # Chuy·ªÉn Series, ndarray th√†nh list; n·∫øu None th√¨ tr·∫£ v·ªÅ []
                        if isinstance(x, (pd.Series, np.ndarray)):
                            return list(x)
                        if x is None:
                            return []
                        return x

                    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o cho chart
                    train_pred_dates = safe_list(train_pred_dates)
                    train_preds = safe_list(train_preds)
                    future_dates = safe_list(future_dates)
                    future_preds = safe_list(future_preds)
                    full_pred_dates = safe_list(full_pred_dates)
                    full_preds = safe_list(full_preds)

                    
                    # Bi·ªÉu ƒë·ªì
                    st.subheader("BI·ªÇU ƒê·ªí D·ª∞ ƒêO√ÅN")
                    fig = go.Figure()

                    # Gi√° th·ª±c t·∫ø
                    fig.add_trace(go.Scatter(
                        x=df['Date'], y=df['Close'],
                        mode='lines', name='Gi√° th·ª±c t·∫ø', line=dict(color='green')
                    ))

                    # 2. ƒê∆∞·ªùng d·ª± ƒëo√°n tr√™n t·∫≠p train (m√†u cam)
                    fig.add_trace(go.Scatter(
                        x=train_pred_dates, y=train_preds,
                        mode='lines', name='D·ª± ƒëo√°n (Train)', line=dict(color='orange', dash='dot')
                    ))

                    # ƒê∆∞·ªùng d·ª± ƒëo√°n t∆∞∆°ng lai, b·∫Øt ƒë·∫ßu t·ª´ ng√†y ti·∫øp theo
                    fig.add_trace(go.Scatter(
                        x=future_dates, y=future_preds,
                        mode='lines', name='D·ª± ƒëo√°n t∆∞∆°ng lai', line=dict(color='red', dash='dot')
                    ))

                    # Gi√° th·ª±c t·∫ø t∆∞∆°ng lai (n·∫øu c√≥, c√≥ th·ªÉ th√™m)
                    if df_real_future is not None and 'Gi√° th·ª±c t·∫ø' in df_real_future.columns:
                        df_merge_plot = pd.merge(pd.DataFrame({'Ng√†y': future_dates}), df_real_future, on='Ng√†y', how='left')
                        if df_merge_plot['Gi√° th·ª±c t·∫ø'].notna().any():
                            fig.add_trace(go.Scatter(
                                x=df_merge_plot['Ng√†y'], y=df_merge_plot['Gi√° th·ª±c t·∫ø'],
                                mode='lines', name='Gi√° th·ª±c t·∫ø t∆∞∆°ng lai', line=dict(color='blue')
                            ))

                    # Layout ƒë·∫πp
                    fig.update_layout(
                        title=f"D·ª± ƒëo√°n gi√° c·ªï phi·∫øu {selected_symbol} ({model_type})",
                        xaxis_title="Ng√†y", yaxis_title="Gi√° c·ªï phi·∫øu",
                        plot_bgcolor='white',
                        xaxis=dict(showgrid=False), yaxis=dict(showgrid=False),
                        height=600,
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                        margin=dict(l=40, r=40, t=80, b=40)
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    # ==== 6. T√≠nh v√† hi·ªÉn th·ªã b·∫£ng ch·ªâ s·ªë l·ªói ====
                    if df_real_future is not None and 'Gi√° th·ª±c t·∫ø' in df_real_future.columns:
                        df_eval = pd.merge(df_pred, df_real_future, on='Ng√†y', how='inner').dropna()
                        if not df_eval.empty:
                            mae = mean_absolute_error(df_eval['Gi√° th·ª±c t·∫ø'], df_eval['Gi√° d·ª± ƒëo√°n'])
                            rmse = np.sqrt(mean_squared_error(df_eval['Gi√° th·ª±c t·∫ø'], df_eval['Gi√° d·ª± ƒëo√°n']))
                            mape = np.mean(np.abs((df_eval['Gi√° th·ª±c t·∫ø'] - df_eval['Gi√° d·ª± ƒëo√°n']) / df_eval['Gi√° th·ª±c t·∫ø'])) * 100

                            st.markdown("### B·∫¢NG CH·ªà S·ªê L·ªñI")
                            df_errors = pd.DataFrame({
                                "MAE": [f"{mae:.2f}"],
                                "RMSE": [f"{rmse:.2f}"],
                                "MAPE (%)": [f"{mape:.2f}"]
                            })
                            st.dataframe(df_errors, use_container_width=True)
                        else:
                            st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh sai s·ªë d·ª± ƒëo√°n t∆∞∆°ng lai.")

                except Exception as e:
                    st.error(f"\u274c L·ªói khi d·ª± ƒëo√°n: {e}")




    if selected_tab == "Model Performance":
        st.markdown("<h1 style='text-align: center;'>SO S√ÅNH HI·ªÜU QU·∫¢ C√ÅC M√î H√åNH</h1>", unsafe_allow_html=True)

        errors_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "errors")

        if os.path.exists(errors_dir):
            error_files = [f for f in os.listdir(errors_dir) if f.endswith('.csv')]

            if error_files:
                all_errors = []

                for error_file in error_files:
                    error_path = os.path.join(errors_dir, error_file)
                    df_error = pd.read_csv(error_path)
                    all_errors.append(df_error)

                df_all_errors = pd.concat(all_errors, ignore_index=True)

                # N√∫t hi·ªÉn th·ªã v√† t·∫£i xu·ªëng
                st.subheader("T·ªïng H·ª£p Ch·ªâ S·ªë L·ªói")
                st.dataframe(df_all_errors, use_container_width=True)

                st.download_button("T·∫£i B·∫£ng L·ªói T·ªïng H·ª£p", df_all_errors.to_csv(index=False).encode('utf-8'),
                                file_name="all_model_errors.csv", mime="text/csv")

            else:
                st.info("Th∆∞ m·ª•c 'errors' ch∆∞a c√≥ file l·ªói n√†o.")
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'errors'.")

        st.markdown("""
            <div style='text-align: center; margin-top: 40px; font-size: 20px; color: gray;'>
                <em>T√≠nh nƒÉng ƒëang ƒë∆∞·ª£c ph√°t tri·ªÉn ‚Äì Coming Soon</em>
            </div>str
        """, unsafe_allow_html=True)




if __name__ == "__main__":
    main()



